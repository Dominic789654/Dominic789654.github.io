<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xiang Liu - PhD Student</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <header>
        <div class="profile-container">
            <img src="images/profile/avatar.png" alt="Xiang Liu" class="profile-photo">
            <div class="profile-info">
                <h1>Xiang Liu (ÂàòÁøî)</h1>
                <p>PhD Student in Data Science and Analytics</p>
                <p>Hong Kong University of Science and Technology (Guangzhou)</p>
                <p><i>Pronouns: he/him</i></p>
            </div>
        </div>
        <div class="contact-links">
            <a href="mailto:xliu886@connect.hkust-gz.edu.cn" title="Email">
                <i class="fas fa-envelope"></i>
            </a>
            <a href="https://scholar.google.com/citations?user=VtK5lwUAAAAJ&hl=zh-CN" target="_blank" title="Google Scholar">
                <i class="fas fa-graduation-cap"></i>
            </a>
            <a href="https://twitter.com/Dominicliu12" target="_blank" title="Twitter">
                <i class="fab fa-twitter"></i>
            </a>
            <a href="https://github.com/Dominic789654" target="_blank" title="GitHub">
                <i class="fab fa-github"></i>
            </a>
            <a href="images/photos/wechat-qr.jpg" target="_blank" title="WeChat" class="wechat-link">
                <i class="fab fa-weixin"></i>
            </a>
            
            <!-- <a href="https://www.kaggle.com/dominic789654" target="_blank" title="Kaggle">
                <i class="fab fa-kaggle"></i>
            </a> -->
        </div>
    </header>

    <main>
        <section id="about">
            <h2>üëã About Me</h2>
            <p>I am a PhD student in Data Science and Analytics (DSA) Thrust at the Hong Kong University of Science and Technology (Guangzhou) advised by <a href="https://sites.google.com/view/chuxiaowen">Prof. Xiaowen Chu</a> and <a href="https://xuminghu.github.io/">Prof. Xuming HU</a>. I have been a research intern at HKUST, working with <a href="https://tongzhang-ml.org/">Prof. Tong Zhang</a>. Prior to HKUST(GZ), I graduated from HKU with an M.S. in Computer Science and GMU with B.S. in Computer science.</p>
        </section>

        <section id="news">
            <h2>üå± What's New</h2>
            <div class="news-container">
                <div class="news-item">
                    <span class="news-badge">New!</span>
                    <p>One paper accepted by AAAI 2024 Oral !!</p>
                </div>
                <div class="news-item">
                    <p>Selected as the <b>Top Reviewer of NeurIPS 2024</b> for both main and D&B tracks</p>
                </div>
                <!-- Add more news items -->
            </div>
        </section>

        <section id="research">
            <h2>üåã Research Interests</h2>
            <p>My main research focuses on natural language processing and machine learning. I am particularly interested in efficient LLMs and Agent. My goal is to build LLMs that can be a daily human assistant.</p>
        </section>

        <section id="publications">
            <h2>üìú Selected Publications</h2>
            <div class="publications-container">
                <div class="publication-item">
                    <h3>ParZC: Parametric Zero-Cost Proxies for Efficient NAS</h3>
                    <p class="authors">Peijie Dong*, Lujun Li*, Xinglin Pan, Zimian Wei, <strong>Xiang Liu</strong>, Qiang Wang, Xiaowen Chu</p>
                    <p class="venue">AAAI 2024. Oral Award.</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2402.02105" target="_blank">Paper</a>
                    </div>
                </div>
                
                <div class="publication-item">
                    <h3>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</h3>
                    <p class="authors">Rui Pan*, <strong>Xiang Liu*</strong>, Shizhe Diao, Renjie Pi, Jipeng Zhang, Chi Han, Tong Zhang</p>
                    <p class="venue">NeurIPS 2024</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2403.17919" target="_blank">Paper</a>
                        <a href="https://github.com/OptimalScale/LMFlow" target="_blank">Code</a>
                        <a href="https://www.jiqizhixin.com/articles/2024-04-01-13" target="_blank">Blog</a>
                    </div>
                </div>
                
                <div class="publication-item">
                    <h3>LongGenBench: Long-context Generation Benchmark</h3>
                    <p class="authors"><strong>Xiang Liu</strong>, Peijie Dong, Xuming Hu, Xiaowen Chu</p>
                    <p class="venue">EMNLP Findings 2024</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2410.04199" target="_blank">Paper</a>
                        <a href="https://github.com/Dominic789654/LongGenBench" target="_blank">Code</a>
                    </div>
                </div>
                
                <div class="publication-item">
                    <h3>Should We Really Edit Language Models? On the Evaluation of Edited Language Models</h3>
                    <p class="authors">Qi Li*, <strong>Xiang Liu*</strong>, Zhenheng Tang, Peijie Dong, Zeyu Li, Xinglin Pan, Xiaowen Chu</p>
                    <p class="venue">NeurIPS 2024</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2410.18785" target="_blank">Paper</a>
                        <a href="https://github.com/lqinfdim/EditingEvaluation" target="_blank">Code</a>
                    </div>
                </div>
                
                <div class="publication-item">
                    <h3>Active prompting with chain-of-thought for large language models</h3>
                    <p class="authors">Shizhe Diao*, Pengcheng Wang*, Yong Lin, Rui Pan, <strong>Xiang Liu</strong>, Tong Zhang</p>
                    <p class="venue">ACL 2024</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2302.12246" target="_blank">Paper</a>
                        <a href="https://github.com/shizhediao/active-prompt" target="_blank">Code</a>
                    </div>
                </div>
            </div>
        </section>

        <section id="preprints">
            <h2>üìù Preprints</h2>
            <div class="publications-container">
                <div class="publication-item">
                    <h3>ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference</h3>
                    <p class="authors"><strong>Xiang Liu</strong>, Zhenheng Tang, Peijie Dong, Zeyu Li, Bo Li, Xuming Hu, Xiaowen Chu</p>
                    <p class="venue">arXiv preprint</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2502.00299" target="_blank">Paper</a>
                    </div>
                </div>

                <div class="publication-item">
                    <h3>Can LLMs Maintain Fundamental Abilities under KV Cache Compression?</h3>
                    <p class="authors"><strong>Xiang Liu</strong>, Zhenheng Tang, Hong Chen, Peijie Dong, Zeyu Li, Xiuze Zhou, Bo Li, Xuming Hu, Xiaowen Chu</p>
                    <p class="venue">arXiv preprint</p>
                    <div class="paper-links">
                        <a href="https://arxiv.org/abs/2502.01941" target="_blank">Paper</a>
                    </div>
                </div>
            </div>
        </section>

        
        <section id="experience">
            <h2>üî¨ Research Experience</h2>
            <div class="experience-container">
                <div class="experience-item">
                    <h3>HKUST(GZ)</h3>
                    <p class="date">09/2023‚ÄìPresent</p>
                    <p>Ph.D. student, supervised by Prof. Xiaowen Chu and Prof. Xuming HU</p>
                </div>
                
                <div class="experience-item">
                    <h3>HKUST</h3>
                    <p class="date">12/2022‚Äì08/2023</p>
                    <p>Research Intern, supervised by Prof. Tong Zhang</p>
                </div>
                
                <div class="experience-item">
                    <h3>Baidu Research Cognitive Computing Lab</h3>
                    <p class="date">12/2021‚Äì06/2022</p>
                    <p>Research Intern, supervised by Mingming Sun</p>
                </div>
            </div>
        </section>

        <section id="service">
            <h2>üí¨ Academic Service</h2>
            <p>Conference Reviewer: ICML2025, ICLR 2025, NeurIPS 2024 (Top Reviewer), ACL (2024-2025), EMNLP (2023 - 2025)</p>
            <p>Journal Reviewer: TMLR</p>
        </section>

        <section id="interests">
            <h2>ü§ó Miscellaneous Interests</h2>
            <ul>
                <li>üè∏ Badminton</li>
                <li>üèãÔ∏è‚Äç‚ôÇÔ∏è Workout</li>
                <li>üèÉ‚Äç‚ôÇÔ∏è Running</li>
            </ul>
        </section>
    </main>

    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=UJZt2W83hovI9mJNzIeO45d5vP1-62SJ5ajCQKOaJNE'></script>
    <footer>
        <p>¬© 2024 Xiang Liu. All rights reserved.</p>
    </footer>

    <script src="script.js"></script>
</body>
</html> 